{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e87a3d-0da3-4178-8b71-aa00c3174626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to CSV files\n",
    "csv_paths = {\n",
    "    \"train\": \"C:/Users/PMLS/Desktop/xloop_project/deepfashion2/img_info_dataframes/train.csv\",\n",
    "    \"validation\": \"C:/Users/PMLS/Desktop/xloop_project/deepfashion2/img_info_dataframes/validation.csv\",\n",
    "    \"test\": \"C:/Users/PMLS/Desktop/xloop_project/deepfashion2/img_info_dataframes/test.csv\"\n",
    "}\n",
    "\n",
    "# Load CSV files into a dictionary\n",
    "csv_data = {key: pd.read_csv(path) for key, path in csv_paths.items()}\n",
    "\n",
    "# Column names\n",
    "image_column = \"path\"  # Ensure this column exists in the CSV\n",
    "width_column = \"img_width\"\n",
    "height_column = \"img_height\"\n",
    "\n",
    "def get_image_size(image_name, dataset_type=\"train\"):\n",
    "    \"\"\"Fetch the image width and height from the CSV files.\"\"\"\n",
    "    df = csv_data.get(dataset_type)\n",
    "    if df is None:\n",
    "        print(f\"Error: No data found for dataset type '{dataset_type}'.\")\n",
    "        return None, None\n",
    "\n",
    "    if image_column not in df.columns:\n",
    "        print(f\"Error: Column '{image_column}' not found in {dataset_type}.csv\")\n",
    "        return None, None\n",
    "\n",
    "    image_name = os.path.basename(image_name)  # Ensure only filename is used\n",
    "    row = df[df[image_column].str.contains(image_name, case=False, na=False)]\n",
    "\n",
    "    if not row.empty:\n",
    "        return int(row[width_column].values[0]), int(row[height_column].values[0])\n",
    "    else:\n",
    "        print(f\"Warning: Image {image_name} not found in {dataset_type}.csv\")\n",
    "        return None, None\n",
    "\n",
    "def convert_annotation(ann_file_path, dataset_type=\"train\"):\n",
    "    \"\"\"Convert annotation JSON file into a YOLO-friendly format.\"\"\"\n",
    "    with open(ann_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract image file name\n",
    "    image_name = os.path.basename(ann_file_path).replace(\".json\", \".jpg\")\n",
    "\n",
    "    # Get image width & height\n",
    "    img_w, img_h = get_image_size(image_name, dataset_type)\n",
    "\n",
    "    if img_w is None or img_h is None:\n",
    "        print(f\"Skipping {image_name}: Could not find image size.\")\n",
    "        return\n",
    "\n",
    "    # Save label file path\n",
    "    label_file_path = ann_file_path.replace(\".json\", \".txt\")\n",
    "\n",
    "    # Open file in write mode\n",
    "    with open(label_file_path, \"w\") as label_file:\n",
    "        # Extract the bounding boxes\n",
    "        for key, item in data.items():\n",
    "            if isinstance(item, dict) and \"bounding_box\" in item:\n",
    "                bbox = item[\"bounding_box\"]\n",
    "                category_id = item[\"category_id\"]\n",
    "\n",
    "                # Convert bbox to YOLO format\n",
    "                x_center = (bbox[0] + bbox[2]) / 2 / img_w\n",
    "                y_center = (bbox[1] + bbox[3]) / 2 / img_h\n",
    "                width = (bbox[2] - bbox[0]) / img_w\n",
    "                height = (bbox[3] - bbox[1]) / img_h\n",
    "\n",
    "                yolo_format = f\"{category_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "                label_file.write(yolo_format)\n",
    "\n",
    "        print(f\"Saved: {label_file_path}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ann_dir = \"C:/Users/PMLS/Desktop/xloop_project/deepfashion2/train/annos/\"\n",
    "for ann_file in os.listdir(ann_dir):\n",
    "    if ann_file.endswith(\".json\"):\n",
    "        convert_annotation(os.path.join(ann_dir, ann_file), dataset_type=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859f469-aeb6-4160-bbab-ccadb6047d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca33a2-b546-48c8-9934-29680c49fabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4796a0-b9dc-46aa-89ee-e91440d3df3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031e206-b611-4368-980a-695cc3106fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac34674-4aaa-4adc-aaac-cf5999381f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
